#region BSD License
/* Copyright (c) 2013-2018, Doxense SAS
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:
	* Redistributions of source code must retain the above copyright
	  notice, this list of conditions and the following disclaimer.
	* Redistributions in binary form must reproduce the above copyright
	  notice, this list of conditions and the following disclaimer in the
	  documentation and/or other materials provided with the distribution.
	* Neither the name of Doxense nor the
	  names of its contributors may be used to endorse or promote products
	  derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
#endregion

namespace FoundationDB.Tests.Sandbox
{
	using System;
	using System.Collections.Generic;
	using System.Diagnostics;
	using System.Globalization;
	using System.Linq;
	using System.Text;
	using System.Threading;
	using System.Threading.Tasks;
	using Doxense.Collections.Tuples;
	using Doxense.Linq;
	using FoundationDB.Client;

	class Program
	{
		private static int N;
		private static string NATIVE_PATH;
		private static string CLUSTER_FILE;
		private static bool WARNING;
		private static string SUBSPACE;

		public static void Main(string[] args)
		{
			N = 10 * 1000;
			NATIVE_PATH = null; // set this to the path of the 'bin' folder in your fdb install, like @"C:\Program Files\foundationdb\bin"
			CLUSTER_FILE = null; // set this to the path to your custom fluster file
			SUBSPACE = "Sandbox";
			WARNING = true;

			for (int i = 0; i < args.Length; i++)
			{
				if (args[i].StartsWith("-") || args[i].StartsWith("/"))
				{
					string cmd = args[i].Substring(1);
					string param = String.Empty;
					int p = cmd.IndexOf('=');
					if (p > 0)
					{
						param = cmd.Substring(p + 1);
						cmd = cmd.Substring(0, p);
						if (param.Length >= 2 && param[0] == '\"' && param[param.Length - 1] == '\"') param = param.Substring(1, param.Length - 2);
					}

					switch (cmd.ToLowerInvariant())
					{
						case "cluster":
						{
							CLUSTER_FILE = param;
							break;
						}
						case "no-warn":
						{
							WARNING = false;
							break;
						}
						case "subspace":
						{
							SUBSPACE = param;
							break;
						}
						case "help":
						{
							DisplayHelp();
							return;
						}
					}
				}
			}

			// Make sure we are on 64 bit
			if (IntPtr.Size == 4)
			{
				Console.Error.WriteLine("This process cannot be run in 32-bit mode !");
				Environment.Exit(-1);
			}

			// Warn the user
			if (WARNING)
			{
				Console.WriteLine("WARNING! WARNING! WARNING!");
				Console.WriteLine("This program will clear all data from your database!");
				Console.WriteLine("Are you sure ? CTRL-C to exit, ENTER to continue");
				Console.ReadLine();
			}

			AppDomain.CurrentDomain.UnhandledException += (object sender, UnhandledExceptionEventArgs e) =>
			{
				if (e.IsTerminating)
					Console.Error.WriteLine("Fatal unhandled exception: " + e.ExceptionObject);
				else
					Console.Error.WriteLine("Unhandled exception: " + e.ExceptionObject);
			};

			using (var go = new CancellationTokenSource())
			{
				try
				{
					ExecuteAsync(MainAsync, go.Token);
				}
				catch (Exception e)
				{
					if (e is AggregateException) e = (e as AggregateException).Flatten().InnerException;
					Console.Error.WriteLine("Oops! something went wrong:");
					Console.Error.WriteLine(e.ToString());
					go.Cancel();
					Environment.ExitCode = -1;
				}
			}
			Console.WriteLine("[PRESS A KEY TO EXIT]");
			Console.ReadKey();
		}

		private static void DisplayHelp()
		{
			Console.WriteLine("Syntax: fdbsandbox [options] [tests]");
			Console.WriteLine("Options:");
			Console.WriteLine("\t-cluster=path\t\tPath to the cluster file to use");
			Console.WriteLine("\t-db=name\t\tName of the database (defaults to 'DB')");
			Console.WriteLine("\t-subspace=prefix\t\tPrefix to use for all tests (defaults to 'Sandbox')");
			Console.WriteLine("\t-no-warn\t\tDisable warning before clearing the subspace");
			Console.WriteLine("\t-help\t\tShow this help text");
		}

		private static async Task MainAsync(CancellationToken ct)
		{
			// change the path to the native lib if not default
			if (NATIVE_PATH != null) Fdb.Options.SetNativeLibPath(NATIVE_PATH);

			// uncomment this to enable network thread tracing
			// FdbCore.TracePath = Path.Combine(Path.GetTempPath(), "fdb");

			int apiVersion = Fdb.GetMaxApiVersion();
			Console.WriteLine("Max API Version: " + apiVersion);

			try
			{
				Console.WriteLine("Starting network thread...");
				Fdb.Start(Fdb.GetDefaultApiVersion());
				Console.WriteLine("> Up and running");

				var settings = new FdbConnectionOptions()
				{
					ClusterFile = CLUSTER_FILE,
					Root = FdbPath.Parse("/Sandbox"),
				};

				Console.WriteLine("Connecting to local cluster...");
				using (var db = await Fdb.OpenAsync(settings, ct))
				{
					Console.WriteLine("> Connected!");

					// get coordinators
					var cf = await Fdb.System.GetCoordinatorsAsync(db, ct);
					Console.WriteLine("Coordinators: " + cf.ToString());

					// clear everything
					using (var tr = await db.BeginTransactionAsync(ct))
					{
						Console.WriteLine("Clearing subspace " + db.Root + " ...");
						var subspace = await db.Root.Resolve(tr);
						tr.ClearRange(subspace);
						await tr.CommitAsync();
						Console.WriteLine("> Database cleared");
					}

					Console.WriteLine();

					await TestSimpleTransactionAsync(db, ct);

					await BenchInsertSmallKeysAsync(db, N, 16, ct); // some guid
					await BenchInsertSmallKeysAsync(db, N, 60 * 4, ct); // one Int32 per minutes, over an hour
					await BenchInsertSmallKeysAsync(db, N, 512, ct); // small JSON payload
					await BenchInsertSmallKeysAsync(db, N / 5, 4096, ct); // typical small cunk size
					await BenchInsertSmallKeysAsync(db, N / 100, 65536, ct); // typical medium chunk size
					await BenchInsertSmallKeysAsync(db, 20, 100_000, ct); // Maximum value size (as of beta 1)

					// insert keys in parrallel
					await BenchConcurrentInsert(db, 1,    100, 512, ct);
					await BenchConcurrentInsert(db, 1,  1_000, 512, ct);
					await BenchConcurrentInsert(db, 1, 10_000, 512, ct);

					await BenchConcurrentInsert(db, 1, N, 16, ct);
					await BenchConcurrentInsert(db, 2, N, 16, ct);
					await BenchConcurrentInsert(db, 4, N, 16, ct);
					await BenchConcurrentInsert(db, 8, N, 16, ct);
					await BenchConcurrentInsert(db, 16, N, 16, ct);

					await BenchSerialWriteAsync(db, N, ct);
					await BenchSerialReadAsync(db, N, ct);
					await BenchConcurrentReadAsync(db, N, ct);

					await BenchClearAsync(db, N, ct);

					await BenchUpdateSameKeyLotsOfTimesAsync(db, 1000, ct);

					await BenchUpdateLotsOfKeysAsync(db, 1000, ct);

					await BenchBulkInsertThenBulkReadAsync(db,   100_000,  50, 128, ct);
					await BenchBulkInsertThenBulkReadAsync(db,   100_000, 128,  50, ct);
					await BenchBulkInsertThenBulkReadAsync(db, 1_000_000,  50, 128, ct);

					await BenchMergeSortAsync(db,   100,     3,  20, ct);
					await BenchMergeSortAsync(db, 1_000,    10, 100, ct);
					await BenchMergeSortAsync(db,   100,   100, 100, ct);
					await BenchMergeSortAsync(db,   100, 1_000, 100, ct);

					Console.WriteLine("time to say goodbye...");
				}
			}
			finally
			{
				Console.WriteLine("### DONE ###");
				Fdb.Stop();
			}
#if DEBUG
			Console.ReadLine();
#endif
		}

		#region Tests...

		private static async Task HelloWorld(CancellationToken ct)
		{

			// Connect to the "DB" database on the local cluster
			using (var db = await Fdb.OpenAsync())
			{

				// Writes some data in to the database
				using (var tr = await db.BeginTransactionAsync(ct))
				{
					tr.Set(TuPack.EncodeKey("Test", 123), Slice.FromString("Hello World!"));
					tr.Set(TuPack.EncodeKey("Test", 456), Slice.FromInt64(DateTime.UtcNow.Ticks));
				}

			}

		}

		private static async Task TestSimpleTransactionAsync(IFdbDatabase db, CancellationToken ct)
		{
			Console.WriteLine("=== TestSimpleTransaction() ===");

			Console.WriteLine("Starting new transaction...");
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				Console.WriteLine("> Transaction ready");

				Console.WriteLine("Getting read version...");
				var readVersion = await trans.GetReadVersionAsync();
				Console.WriteLine("> Read Version = " + readVersion);

				Console.WriteLine("Resolving root location...");
				var location = await db.Root.Resolve(trans);
				Console.WriteLine("> " + location);

				Console.WriteLine("Getting 'hello'...");
				var result = await trans.GetAsync(location.Encode("hello"));
				if (result.IsNull)
					Console.WriteLine("> hello NOT FOUND");
				else
					Console.WriteLine($"> hello = {result:V}");

				Console.WriteLine("Setting 'Foo' = 'Bar'");
				trans.Set(location.Encode("Foo"), Slice.FromString("Bar"));

				Console.WriteLine("Setting 'TopSecret' = rnd(512)");
				var data = new byte[512];
				new Random(1234).NextBytes(data);
				trans.Set(location.Encode("TopSecret"), data.AsSlice());

				Console.WriteLine("Committing transaction...");
				await trans.CommitAsync();
				//trans.Commit();
				Console.WriteLine("> Committed!");

				Console.WriteLine("Getting comitted version...");
				var writeVersion = trans.GetCommittedVersion();
				Console.WriteLine("> Commited Version = " + writeVersion);
			}
		}

		private static async Task BenchInsertSmallKeysAsync(IFdbDatabase db, int N, int size, CancellationToken ct)
		{
			// insert a lot of small key size, in a single transaction

			Console.WriteLine($"=== BenchInsertSmallKeys(N={N:N0}, size={size:N0}) ===");

			var rnd = new Random();
			var tmp = new byte[size];

			var location = db.Root.ByKey("Batch");

			var times = new List<TimeSpan>();
			for (int k = 0; k <= 4; k++)
			{
				var sw = Stopwatch.StartNew();
				using (var trans = await db.BeginTransactionAsync(ct))
				{
					var subspace = await location.Resolve(trans);

					rnd.NextBytes(tmp);
					for (int i = 0; i < N; i++)
					{
						tmp[0] = (byte)i;
						tmp[1] = (byte)(i >> 8);
						// (Batch, 1) = [......]
						// (Batch, 2) = [......]
						trans.Set(subspace.Encode(k * N + i), tmp.AsSlice());
					}
					await trans.CommitAsync();
				}
				sw.Stop();
				times.Add(sw.Elapsed);
			}
			var min = times.Min();
			var avg = times.Sum(x => x.TotalMilliseconds)/times.Count;
			Console.WriteLine($"[{Thread.CurrentThread.ManagedThreadId}] Took {min.TotalSeconds.ToString("N3", CultureInfo.InvariantCulture)} sec to insert {N} {size}-bytes items (min={FormatTimeMicro(min.TotalMilliseconds / N)}/write, avg={FormatTimeMicro(avg)}/write)");
			Console.WriteLine();
		}

		private static async Task BenchConcurrentInsert(IFdbDatabase db, int k, int N, int size, CancellationToken ct)
		{
			// insert a lot of small key size, in multiple batch running in //
			// k = number of threads
			// N = total number of keys
			// size = value size (bytes)
			// n = keys per batch (N/k)

			int n = N / k;
			// make sure that N is multiple of k
			N = n * k;

			Console.WriteLine($"=== BenchConcurrentInsert(k={k:N0}, N={N:N0}, size={size:N0}) ===");
			Console.WriteLine($"Inserting {N:N0} keys in {k:N0} batches of {n:N0} with {size:N0}-bytes values...");

			// store every key under ("Batch", i)
			// total estimated size of all transactions
			long totalPayloadSize = 0;

			var location = db.Root.AsBinary();

			var tasks = new List<Task>();
			var sem = new ManualResetEventSlim();
			for (int j = 0; j < k; j++)
			{
				int offset = j;
				// spin a task for the batch using TaskCreationOptions.LongRunning to make sure it runs in its own thread
				tasks.Add(Task.Factory.StartNew(async () =>
				{
					var rnd = new Random(1234567 * j);
					var tmp = new byte[size];
					rnd.NextBytes(tmp);

					// block until all threads are ready
					sem.Wait();

					var x = Stopwatch.StartNew();
					using (var trans = await db.BeginTransactionAsync(ct))
					{
						x.Stop();
						//Console.WriteLine($"> [{offset}] got transaction in {FormatTimeMilli(x.Elapsed.TotalMilliseconds)}");

						var subspace = await location.Resolve(trans);

						// package the keys...
						x.Restart();
						for (int i = 0; i < n; i++)
						{
							// change the value a little bit
							tmp[0] = (byte)i;
							tmp[1] = (byte)(i >> 8);

							// ("Batch", batch_index, i) = [..random..]
							trans.Set(subspace[Slice.FromFixed64BE(i)], tmp.AsSlice());
						}
						x.Stop();
						//Console.WriteLine($"> [{offset}] packaged {n:N0} keys ({trans.Size:N0} bytes) in {FormatTimeMilli(x.Elapsed.TotalMilliseconds)}");

						// commit the transaction
						x.Restart();
						await trans.CommitAsync();
						x.Stop();
						//Console.WriteLine($"> [{offset}] committed {n} keys ({trans.Size:N0} bytes) in {FormatTimeMilli(x.Elapsed.TotalMilliseconds)}");

						Interlocked.Add(ref totalPayloadSize, trans.Size);
					}

				}, TaskCreationOptions.LongRunning).Unwrap());
			}
			// give time for threads to be ready
			await Task.Delay(100);

			// start
			var sw = Stopwatch.StartNew();
			sem.Set();

			// wait for total completion
			await Task.WhenAll(tasks);
			sw.Stop();
			Console.WriteLine($"* Total: {FormatTimeMilli(sw.Elapsed.TotalMilliseconds)}, {FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)} / write, {FormatThroughput(totalPayloadSize, sw.Elapsed.TotalSeconds)}, {N / sw.Elapsed.TotalSeconds:N0} write/sec");
			Console.WriteLine();
		}

		private static async Task BenchSerialWriteAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// read a lot of small keys, one by one

			Console.WriteLine($"=== BenchSerialWrite(N={N:N0}) ===");

			var location = db.Root.ByKey("hello");
			var sw = Stopwatch.StartNew();
			IFdbTransaction trans = null;
			IDynamicKeySubspace subspace = null;
			try
			{
				for (int i = 0; i < N; i++)
				{
					if (trans == null)
					{
						trans = await db.BeginTransactionAsync(ct);
						subspace = await location.Resolve(trans);
					}
					trans.Set(subspace.Encode(i), Slice.FromInt32(i));
					if (trans.Size > 100 * 1024)
					{
						await trans.CommitAsync();
						trans.Dispose();
						trans = null;
					}
				}
				await trans.CommitAsync();
			}
			finally
			{
				trans?.Dispose();
			}
			sw.Stop();
			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to read {N:N0} items ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)}/read, {N/sw.Elapsed.TotalSeconds:N0} read/sec)");
			Console.WriteLine();
		}

		private static async Task BenchSerialReadAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// read a lot of small keys, one by one

			Console.WriteLine($"=== BenchSerialRead(N={N:N0}) ===");
			Console.WriteLine($"Reading {N:N0} keys (serial, slow!)");

			var location = db.Root.ByKey("hello");

			var sw = Stopwatch.StartNew();
			for (int k = 0; k < N; k += 1000)
			{
				using (var trans = await db.BeginTransactionAsync(ct))
				{
					var subspace = await location.Resolve(trans);
					for (int i = k; i < N && i < k + 1000; i++)
					{
						_ = await trans.GetAsync(subspace.Encode(i));
					}
				}
				Console.Write(".");
			}
			Console.WriteLine();
			sw.Stop();
			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to read {N:N0} items ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)}/read, {N / sw.Elapsed.TotalSeconds:N0} read/sec)");
			Console.WriteLine();
		}

		private static async Task BenchConcurrentReadAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// read a lot of small keys, concurrently

			Console.WriteLine($"=== BenchConcurrentRead(N={N:N0}) ===");
			Console.WriteLine($"Reading {N:N0} keys (concurrent)");

			var location = db.Root.ByKey("hello").AsTyped<int>();

			var sw = Stopwatch.StartNew();
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(trans);
				_ = await Task.WhenAll(Enumerable
					.Range(0, N)
					.Select((i) => trans.GetAsync(subspace[i]))
				);
			}
			sw.Stop();
			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to read {N} items ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)}/read, {N / sw.Elapsed.TotalSeconds:N0} read/sec)");
			Console.WriteLine();

			sw = Stopwatch.StartNew();
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(trans);
				_ = await trans.GetBatchAsync(Enumerable.Range(0, N).Select(i => subspace[i]));
			}
			sw.Stop();
			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to read {N:N0} items ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)}/read, {N / sw.Elapsed.TotalSeconds:N0} read/sec)");
			Console.WriteLine();
		}

		private static async Task BenchClearAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// clear a lot of small keys, in a single transaction

			Console.WriteLine($"=== BenchClear(N={N:N0}) ===");

			var location = db.Root.ByKey(Slice.FromStringAscii("hello"));

			var sw = Stopwatch.StartNew();
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(trans);
				for (int i = 0; i < N; i++)
				{
					trans.Clear(subspace.Encode(i));
				}

				await trans.CommitAsync();
			}
			sw.Stop();
			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to clear {N:N0} items ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)}/write, {N / sw.Elapsed.TotalSeconds:N0} clear/sec)");
			Console.WriteLine();
		}

		private static async Task BenchUpdateSameKeyLotsOfTimesAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// continuously update same key by adding a little bit more

			Console.WriteLine($"=== BenchUpdateSameKeyLotsOfTimes(N={N:N0}) ===");
			Console.WriteLine($"Updating the same list {N:N0} times...");

			var list = new byte[N];
			var update = Stopwatch.StartNew();
			for (int i = 0; i < N; i++)
			{
				list[i] = (byte)i;
				using (var trans = await db.BeginTransactionAsync(ct))
				{
					var subspace = await db.Root.Resolve(trans);
					trans.Set(subspace.Encode("list"), list.AsSlice());
					await trans.CommitAsync();
				}
				if (i % 100 == 0) Console.Write($"\r> {i:N0} / {N:N0}");
			}
			update.Stop();

			Console.WriteLine($"\rTook {update.Elapsed.TotalSeconds:N3} sec to fill a byte[{N:N0}] one by one ({FormatTimeMicro(update.Elapsed.TotalMilliseconds / N)}/update, {N / update.Elapsed.TotalSeconds:N0} update/sec)");
			Console.WriteLine();
		}

		private static async Task BenchUpdateLotsOfKeysAsync(IFdbDatabase db, int N, CancellationToken ct)
		{
			// change one byte in a large number of keys

			Console.WriteLine($"=== BenchUpdateLotsOfKeys(N={N:N0}) ===");

			var location = db.Root.ByKey("lists").AsTyped<int>();

			var rnd = new Random();

			Console.WriteLine($"> creating {N:N0} half filled keys");
			var segment = new byte[60];

			for (int i = 0; i < (segment.Length >> 1); i++) segment[i] = (byte) rnd.Next(256);
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(trans);
				for (int i = 0; i < N; i += 1000)
				{
					for (int k = i; k < i + 1000 && k < N; k++)
					{
						trans.Set(subspace[k], segment.AsSlice());
					}
					await trans.CommitAsync();
					Console.Write("\r" + i + " / " + N);
				}
			}

			Console.WriteLine($"\rChanging one byte in each of the {N:N0} keys...");
			var sw = Stopwatch.StartNew();
			using (var trans = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(trans);

				Console.WriteLine("READ");
				// get all the lists
				var data = await trans.GetBatchAsync(Enumerable.Range(0, N).Select(i => subspace[i]));

				// change them
				Console.WriteLine("CHANGE");
				for (int i = 0; i < data.Length; i++)
				{
					var list = data[i].Value.GetBytes();
					list[(list.Length >> 1) + 1] = (byte) rnd.Next(256);
					trans.Set(data[i].Key, list.AsSlice());
				}

				Console.WriteLine("COMMIT");
				await trans.CommitAsync();
			}
			sw.Stop();

			Console.WriteLine($"Took {sw.Elapsed.TotalSeconds:N3} sec to patch one byte in {N:N0} lists ({FormatTimeMicro(sw.Elapsed.TotalMilliseconds / N)} /update, {N / sw.Elapsed.TotalSeconds:N0} update/sec)");
			Console.WriteLine();
		}

		private static async Task BenchBulkInsertThenBulkReadAsync(IFdbDatabase db, int N, int K, int B, CancellationToken ct, bool instrumented = false)
		{
			// test that we can bulk write / bulk read

			Console.WriteLine($"=== BenchBulkInsertThenBulkRead(N={N:N0}, K={K:N0}, B={B:N0}) ===");

			var timings = instrumented ? new List<KeyValuePair<double, double>>() : null;

			// put test values inside a namespace
			var location = db.Root.ByKey("BulkInsert");

			// cleanup everything
			using (var tr = await db.BeginTransactionAsync(ct))
			{
				tr.ClearRange(await location.Resolve(tr));
				await tr.CommitAsync();
			}

			// insert all values (batched)
			Console.WriteLine($"Inserting {N:N0} keys: ");
			var insert = Stopwatch.StartNew();
			int batches = 0;
			long bytes = 0;

			var start = Stopwatch.StartNew();

			var tasks = new List<Task>();
			foreach (var worker in FdbKey.Batched(0, N, K, B))
			{
				//hack
				tasks.Add(Task.Run(async () =>
				{
					foreach (var chunk in worker)
					{
						using (var tr = await db.BeginTransactionAsync(ct))
						{
							var subspace = await location.Resolve(tr);
							int z = 0;
							foreach (int i in Enumerable.Range(chunk.Key, chunk.Value))
							{
								tr.Set(subspace.Encode(i), Slice.Zero(256));
								z++;
							}

							//Console.Write("#");
							//Console.WriteLine("  Commiting batch (" + tr.Size.ToString("N0", CultureInfo.InvariantCulture) + " bytes) " + z + " keys");
							var localStart = start.Elapsed.TotalSeconds;
							await tr.CommitAsync();
							var localDuration = start.Elapsed.TotalSeconds - localStart;
							if (instrumented)
							{
								lock (timings) { timings.Add(new KeyValuePair<double, double>(localStart, localDuration)); }
							}
							Interlocked.Increment(ref batches);
							Interlocked.Add(ref bytes, tr.Size);
						}

					}
				}, ct));

			}
			await Task.WhenAll(tasks);

			insert.Stop();
			Console.WriteLine($"Committed {batches:N0} batches in {FormatTimeMilli(insert.Elapsed.TotalMilliseconds)} ({FormatTimeMilli(insert.Elapsed.TotalMilliseconds / batches)} / batch, {FormatTimeMicro(insert.Elapsed.TotalMilliseconds / N)} / item)");
			Console.WriteLine($"Throughput {FormatThroughput(bytes, insert.Elapsed.TotalSeconds)}, {N / insert.Elapsed.TotalSeconds:N0} write/sec");

			if (instrumented)
			{
				var sb = new StringBuilder();
				foreach (var kvp in timings)
				{
					sb.Append(kvp.Key.ToString()).Append(';').Append((kvp.Key + kvp.Value).ToString()).Append(';').Append(kvp.Value.ToString()).AppendLine();
				}
#if DEBUG
				System.IO.File.WriteAllText(@"c:\temp\fdb\timings_" + N + "_" + K + "_" + B + ".csv", sb.ToString());
#else
				Console.WriteLine(sb.ToString());
#endif
			}

			// Read values

			using (var tr = await db.BeginTransactionAsync(ct))
			{
				Console.WriteLine("Reading all keys...");
				var subspace = await location.Resolve(tr);
				var sw = Stopwatch.StartNew();
				var items = await tr.GetRange(subspace.ToRange()).ToListAsync();
				sw.Stop();
				Console.WriteLine($"Took {FormatTimeMilli(sw.Elapsed.TotalMilliseconds)} to get {items.Count.ToString("N0", CultureInfo.InvariantCulture)} results ({items.Count / sw.Elapsed.TotalSeconds:N0} keys/sec)");
			}

			Console.WriteLine();
		}

		private static async Task BenchMergeSortAsync(IFdbDatabase db, int N, int K, int B, CancellationToken ct)
		{
			Console.WriteLine($"=== BenchMergeSort(N={N:N0}, K={K:N0}, B={B:N0}) ===");

			// create multiple lists
			var location = db.Root.ByKey("MergeSort");
			await db.WriteAsync(async tr =>
			{
				var subspace = await location.Resolve(tr);
				tr.ClearRange(subspace);
			}, ct);

			var sources = Enumerable.Range(0, K).Select(i => 'A' + i).ToArray();
			var rnd = new Random();

			// insert a number of random number lists
			Console.Write($"> Inserting {(K * N):N0} items... ");
			foreach (var source in sources)
			{
				using (var tr = await db.BeginTransactionAsync(ct))
				{
					var list = await location.ByKey(source).Resolve(tr);
					for (int i = 0; i < N; i++)
					{
						tr.Set(list.Encode(rnd.Next()), Slice.FromInt32(i));
					}
					await tr.CommitAsync();
				}
			}
			Console.WriteLine("Done");

			// merge/sort them to get only one (hopefully sorted) list

			using (var tr = await db.BeginTransactionAsync(ct))
			{
				var subspace = await location.Resolve(tr);

				var mergesort = tr
					.MergeSort(
						sources.Select(source => KeySelectorPair.StartsWith(subspace.Encode(source))),
						(kvp) => subspace.DecodeLast<int>(kvp.Key)
					)
					.Take(B)
					.Select(kvp => subspace.Unpack(kvp.Key));

				Console.Write($"> MergeSort with limit {B:N0}... ");
				var sw = Stopwatch.StartNew();
				var results = await mergesort.ToListAsync();
				sw.Stop();
				Console.WriteLine("Done");

				Console.WriteLine($"Took {FormatTimeMilli(sw.Elapsed.TotalMilliseconds)} to merge sort {results.Count:N0} results from {K} lists of {N} items each");

				//foreach (var result in results)
				//{
				//	Console.WriteLine(result.Get<int>(-1));
				//}
			}
			Console.WriteLine();
		}

		#endregion

		#region Helpers...

		private static void ExecuteAsync(Func<CancellationToken, Task> code, CancellationToken ct)
		{
			// poor man's async main loop
			Task.Run(() => code(ct), ct).GetAwaiter().GetResult();
		}

		private static string FormatTimeMilli(double ms)
		{
			return ms.ToString("N3", CultureInfo.InvariantCulture) + " ms";
		}

		private static string FormatTimeMicro(double ms)
		{
			return (ms * 1E3).ToString("N1", CultureInfo.InvariantCulture) + " µs";
		}

		private static string FormatThroughput(long bytes, double secs)
		{
			if (secs == 0) return "0";

			double bw = bytes / secs;

			if (bw < 1024) return bw.ToString("N0", CultureInfo.InvariantCulture) + " bytes/sec";
			if (bw < (1024 * 1024)) return (bw / 1024).ToString("N1", CultureInfo.InvariantCulture) + " kB/sec";
			return (bw / (1024 * 1024)).ToString("N3", CultureInfo.InvariantCulture) + " MB/sec";
		}

		#endregion

	}
}
